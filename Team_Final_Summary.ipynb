{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Data Science and Stem Salaries - How to land in a high Paying jobs\"\n",
        "author: Brooklyn Chen, Manojkumar Yerraguntla, Nayaeun Kwon\n",
        "format:\n",
        "    html:    \n",
        "        code-fold: true\n",
        "        number-sections: true\n",
        "        toc: true\n",
        "        toc-depth: 6\n",
        "        toc-float: true\n",
        "        toc-location: left\n",
        "execute: \n",
        "  echo: false\n",
        "  result: hide\n",
        "  warning: false\n",
        "---"
      ],
      "id": "75b4cdd0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction\n",
        "\n",
        "## Data Science and Stem Salaries\n",
        "\n",
        "## Prior Reserch and Analysis\n",
        "\n",
        "## About the Dataset\n",
        "\n",
        "This dataset is collected from Kaggle in order to explore Data Science and Stem Salaries.\n",
        "\n",
        "Our original dataset has approximately 62,000 observations with 29 features.\n",
        "\n",
        "There are some duplicates, null values and outliers in our dataset. After removing the duplicates, null values and outliers in our dataset we are left with 35973 observations.\n",
        "\n",
        "\n",
        "\n",
        "We have considered the below mentioned features in our final dataset:\n",
        "\n",
        "timestamp: When the data was recorded\n",
        "company: Company name into which employee got selected\n",
        "title: Jop title of the employee\n",
        "yearlysalary: Amount of salary earned by the employee\n",
        "location: Job location \n",
        "yearsofexperience: Year of Experience\n",
        "yearsatcompany: Years of experience at same company\n",
        "gender: Male or Female \n"
      ],
      "id": "a97743ba"
    },
    {
      "cell_type": "code",
      "metadata": {
        "Importing the Libraries": null
      },
      "source": [
        "#| output: false\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import scipy.stats as stats\n",
        "import sklearn\n",
        "import researchpy as rp\n",
        "from scipy.stats import pearsonr\n",
        "import pandas_profiling as pp\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.colheader_justify', 'center')\n",
        "pd.set_option('display.precision', 3)"
      ],
      "id": "fddb668f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| output: false\n",
        "\n",
        "# Important the Salary DataSet from .CSV file\n",
        "old_df=pd.read_csv('Levels_Fyi_Salary_Data.csv')\n",
        "\n",
        "# Explore Dataset\n",
        "old_dfprofile = pp.ProfileReport(old_df)\n",
        "\n",
        "# Creating a new dataframe with selected Features\n",
        "df = old_df[['timestamp','company','title','yearsofexperience','yearsatcompany', 'gender', 'location']]\n",
        "\n",
        "# Renaming the Totalyearlycompensation variable name into yearlysalary\n",
        "df['yearlysalary'] = old_df['totalyearlycompensation']\n",
        "\n",
        "# Coverting timestamp feature from MM-DD-YYYY HH:MM:SS format to YYYY format\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%Y')"
      ],
      "id": "5b052c95",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Salary histogram for checking normality before removing NA Values, Duplicates and Outliers."
      ],
      "id": "bfb96233"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# salary histogram for checking normality\n",
        "sns.distplot(df.yearlysalary, fit = stats.norm)"
      ],
      "id": "fe8a5318",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Removing a row which has irrelavent value for feature Gender='Title: Senior Software Engineer'\n",
        "df=df.drop(labels=11010,axis=0)\n",
        "\n",
        "# checking for number of duplicates\n",
        "df.duplicated().sum()\n",
        "\n",
        "# Removing the duplicates from the dataframe\n",
        "df.drop_duplicates(keep=False,inplace=True)\n",
        "\n",
        "# Checking the number of null values \n",
        "df.isnull().sum()\n",
        "\n",
        "# Removing the null values\n",
        "df=df.dropna()\n",
        "\n",
        "# Removing the Outliers on the basis of yearlysalary\n",
        "df1 = df.copy()\n",
        "print (\"Shape Of The Before removing yearlysalary Outliers: \",df.shape)\n",
        "n=1.5\n",
        "IQR_1 = np.percentile(df1['yearlysalary'],75) - np.percentile(df1['yearlysalary'],25)\n",
        "#outlier = Q3 + n*IQR 8\n",
        "df1=df1[df1['yearlysalary'] < np.percentile(df1['yearlysalary'],75)+n*IQR_1]\n",
        "#outlier = Q1 - n*IQR \n",
        "df1=df1[df1['yearlysalary'] > np.percentile(df1['yearlysalary'],25)-n*IQR_1]\n",
        "print (\"Shape Of The After removing yearlysalary Outliers: \",df1.shape)\n",
        "\n",
        "# Removing the Outliers on the basis of yearsatcompany\n",
        "df2 = df1.copy()\n",
        "print (\"Shape Of The Before removing yearsatcompany at Outliers: \",df1.shape)\n",
        "n=1.5\n",
        "IQR_2 = np.percentile(df2['yearsatcompany'],75) - np.percentile(df2['yearsatcompany'],25)\n",
        "#outlier = Q3 + n*IQR \n",
        "df2=df2[df2['yearsatcompany'] < np.percentile(df2['yearsatcompany'],75)+n*IQR_2]\n",
        "#outlier = Q1 - n*IQR \n",
        "df2=df2[df2['yearsatcompany'] > np.percentile(df2['yearsatcompany'],25)-n*IQR_2]\n",
        "print (\"Shape Of The After removing yearsatcompany Outliers: \",df2.shape)\n",
        "\n",
        "# Removing the Outliers on the basis of yearsofexperience\n",
        "df3 = df2.copy()\n",
        "print (\"Shape Of The Before removing yearsofexperience Outliers: \",df2.shape)\n",
        "n=1.5\n",
        "IQR_3 = np.percentile(df3['yearsofexperience'],75) - np.percentile(df3['yearsofexperience'],25)\n",
        "#outlier = Q3 + n*IQR \n",
        "df3=df3[df3['yearsofexperience'] < np.percentile(df3['yearsofexperience'],75)+n*IQR_3]\n",
        "#outlier = Q1 - n*IQR \n",
        "df3=df3[df3['yearsofexperience'] > np.percentile(df3['yearsofexperience'],25)-n*IQR_3]\n",
        "print (\"Shape Of The After removing yearsofexperience Outliers: \",df3.shape)\n",
        "\n",
        "dataframe=df3\n",
        "# Observing the first five rows of the dataframe after removing duplicates, null values, and Outliers\n",
        "df3.head()\n",
        "\n",
        "# Descriptive Statistics Summary of the dataframe after removing duplicates, null values, and Outliers\n",
        "df3.describe()"
      ],
      "id": "62bab841",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Salary histogram for checking normality after removing NA Values, Duplicates and Outliers."
      ],
      "id": "c528e349"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# salary histogram for chekciing normality\n",
        "sns.distplot(df3.yearlysalary, fit = stats.norm)"
      ],
      "id": "b7d890ad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis\n",
        "\n",
        "## Which job position has highest earning? Over time, salary by job title is changed?\n",
        "\n",
        "Unique titles in our dataset"
      ],
      "id": "a512fcf5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print (pd.unique(df3.title))\n",
        "print (df3['title'].nunique())"
      ],
      "id": "0386d865",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Piechart for each job title and their repsective percentages"
      ],
      "id": "17697cc1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print (df3['title'].value_counts())\n",
        "fig = px.pie(df3, names = 'title', title = 'Title')\n",
        "fig.show()"
      ],
      "id": "bf4cbf1a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Avg salary by title"
      ],
      "id": "e698f846"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "avgsalary = df3.groupby('title').mean()['yearlysalary'].reset_index()\n",
        "print (avgsalary)\n",
        "\n",
        "avgsalary.plot(kind = 'bar', x = 'title', y = 'yearlysalary', title = 'Average Salary by Job Title', figsize=(15,8))\n",
        "plt.show()\n",
        "\n",
        "\n",
        "clarity_ranking = [\"Product Manager\", \"Software Engineer\", \"Software Engineering Manager\", \"Data Scientist\", \"Solution Architect\", \"Technical Program Manager\", \"Human Resources\", \"Product Designer\", \"Marketing\", \"Business Analyst\", \"Hardware Engineer\", \"Sales\", \"Recruiter\", \"Mechanical Engineer\", \"Management Consultant\"]\n",
        "\n",
        "titleboxplot = sns.boxplot(y=\"title\", x=\"yearlysalary\", color=\"b\", order=clarity_ranking, data=df3, showfliers = False, palette=\"Blues\", orient=\"h\")\n",
        "titleboxplot.axes.set_title(\"Salary Box Plot by Job Title\", fontsize=16)\n",
        "titleboxplot.set_xlabel(\"Job Title\", fontsize=14)\n",
        "titleboxplot.set_ylabel(\"Yearly Salary\", fontsize=14)\n",
        "plt.setp(titleboxplot.get_xticklabels(), rotation=90)\n",
        "\n",
        "plt.show()"
      ],
      "id": "702c8a2e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Software engineering manager has highest earning.\n",
        "\n",
        "2018 top 5 highest earner"
      ],
      "id": "e22fa14c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 2018 top 5 highest earner\n",
        "df2018 = df3[df3.timestamp=='2018']\n",
        "highearn1 = df2018.groupby(['title','yearsofexperience','company', 'location']).max()['yearlysalary'].reset_index()\n",
        "highearn1 = highearn1.nlargest(5, ['yearlysalary'])\n",
        "highearn1"
      ],
      "id": "8be89125",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In 2018, highest job positions are Software Engineer, Data Scientist, Software Engineering Manager.\n",
        "\n",
        "2019 top 10 highest earner"
      ],
      "id": "6eeba0d4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 2019 top 10 highest earner\n",
        "\n",
        "df2019 = df3[df3.timestamp=='2019']\n",
        "highearn2 = df2019.groupby(['title','yearsofexperience','company', 'location']).max()['yearlysalary'].reset_index()\n",
        "highearn2 = highearn2.nlargest(5, ['yearlysalary'])\n",
        "\n",
        "highearn2"
      ],
      "id": "2156565c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In 2019, highest job positions are Product Manager, Software Engineer, Software Engineering Manager.\n",
        "\n",
        "2020 top 10 highest earner"
      ],
      "id": "a9cfbd09"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 2020 top 10 highest earner\n",
        "\n",
        "df2020 = df3[df3.timestamp=='2020']\n",
        "highearn3 = df2020.groupby(['title','yearsofexperience','company', 'location']).max()['yearlysalary'].reset_index()\n",
        "highearn3 = highearn3.nlargest(5, ['yearlysalary'])\n",
        "\n",
        "highearn3"
      ],
      "id": "0b67884d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In 2020, highest job positions are Software Engineer, Software Engineering Manager, Hardware Engineer, Product Manager, Data Scientist.\n",
        "\n",
        "2021 top 10 highest earner"
      ],
      "id": "e1f61e07"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 2021 top 10 highest earner\n",
        "\n",
        "df2021 = df3[df3.timestamp=='2021']\n",
        "highearn4 = df2021.groupby(['title','yearsofexperience','company', 'location']).max()['yearlysalary'].reset_index()\n",
        "highearn4 = highearn4.nlargest(5, ['yearlysalary'])\n",
        "\n",
        "highearn4"
      ],
      "id": "126fa28f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In 2021, highest job positions are Software Engineer, Software Engineering Manager, Data Scientist, Product Manager.\n",
        "\n",
        "From 2018 to 2021, job position such as Software Engineer, Software Engineering Manager, Data Scientist, Product Manager, Hardware Engineer made highly earning. \n",
        "\n",
        "\n",
        "Hypothesis Testing for the salary of the job position per year\n"
      ],
      "id": "6ced3011"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# H₀: Year by year salary means of software engineer are equal.\n",
        "# H₁: Year by year salary means of software engineer are not equal.\n",
        "# α = 0.05\n",
        "\n",
        "SE = df3[df3['title'] == 'Software Engineer']\n",
        "\n",
        "SE_ANOVA = [['Between Groups', '', '', '', '', '', ''], ['Within Groups', '', '', '', '', '', ''], ['Total', '', '', '', '', '', '']] \n",
        "SE_anova_table = pd.DataFrame(SE_ANOVA, columns = ['Source of Variation', 'SS', 'df', 'MS', 'F', 'P-value', 'F crit']) \n",
        "SE_anova_table.set_index('Source of Variation', inplace = True)\n",
        "\n",
        "# calculate SSTR and update anova table\n",
        "x_bar = SE['yearlysalary'].mean()\n",
        "SSTR = SE.groupby('timestamp').count() * (SE.groupby('timestamp').mean() - x_bar)**2       \n",
        "SE_anova_table['SS']['Between Groups'] = SSTR['yearlysalary'].sum()\n",
        "\n",
        "# calculate SSE and update anova table\n",
        "SSE = (SE.groupby('timestamp').count() - 1) * SE.groupby('timestamp').std()**2\n",
        "SE_anova_table['SS']['Within Groups'] = SSE['yearlysalary'].sum()\n",
        "\n",
        "# calculate SSTR and update anova table\n",
        "SSTR = SSTR['yearlysalary'].sum() + SSE['yearlysalary'].sum()\n",
        "SE_anova_table['SS']['Total'] = SSTR\n",
        "\n",
        "# update degree of freedom\n",
        "SE_anova_table['df']['Between Groups'] = SE['timestamp'].nunique() - 1\n",
        "SE_anova_table['df']['Within Groups'] = SE.shape[0] - SE['timestamp'].nunique()\n",
        "SE_anova_table['df']['Total'] = SE.shape[0] - 1\n",
        "\n",
        "# calculate MS\n",
        "SE_anova_table['MS'] = SE_anova_table['SS'] / SE_anova_table['df']\n",
        "\n",
        "# calculate F \n",
        "F = SE_anova_table['MS']['Between Groups'] / SE_anova_table['MS']['Within Groups']\n",
        "SE_anova_table['F']['Between Groups'] = F\n",
        "\n",
        "# p-value\n",
        "SE_anova_table['P-value']['Between Groups'] = 1 - stats.f.cdf(F, SE_anova_table['df']['Between Groups'], SE_anova_table['df']['Within Groups'])\n",
        "\n",
        "# F critical \n",
        "alpha = 0.01\n",
        "# possible types \"right-tailed, left-tailed, two-tailed\"\n",
        "tail_hypothesis_type = \"two-tailed\"\n",
        "if tail_hypothesis_type == \"two-tailed\":\n",
        "    alpha /= 2\n",
        "SE_anova_table['F crit']['Between Groups'] = stats.f.ppf(1-alpha, SE_anova_table['df']['Between Groups'], SE_anova_table['df']['Within Groups'])\n",
        "\n",
        "# Final ANOVA Table\n",
        "SE_anova_table"
      ],
      "id": "e74714db",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"The p-value approach to hypothesis testing in the decision rule\")\n",
        "conclusion = \"Failed to reject the null hypothesis.\"\n",
        "if SE_anova_table['P-value']['Between Groups'] <= alpha:\n",
        "    conclusion = \"Null Hypothesis is rejected.\"\n",
        "print(\"F-score is:\", SE_anova_table['F']['Between Groups'], \" and p value is:\", SE_anova_table['P-value']['Between Groups'])    \n",
        "print(conclusion)\n",
        "\n",
        "# Reject H0"
      ],
      "id": "886cf91a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# H₀: Year by year salary means of Software Engineering Manager are equal.\n",
        "# H₁: Year by year salary means of Software Engineering Manager are not equal.\n",
        "# α = 0.05\n",
        "\n",
        "# Data Scientist, Product Manager, Hardware Engineer\n",
        "SEM = df3[df3['title'] == 'Software Engineering Manager']\n",
        "\n",
        "SEM_ANOVA = [['Between Groups', '', '', '', '', '', ''], ['Within Groups', '', '', '', '', '', ''], ['Total', '', '', '', '', '', '']] \n",
        "SEM_anova_table = pd.DataFrame(SEM_ANOVA, columns = ['Source of Variation', 'SS', 'df', 'MS', 'F', 'P-value', 'F crit']) \n",
        "SEM_anova_table.set_index('Source of Variation', inplace = True)\n",
        "\n",
        "# calculate SSTR and update anova table\n",
        "x_bar = SEM['yearlysalary'].mean()\n",
        "SSTR = SEM.groupby('timestamp').count() * (SEM.groupby('timestamp').mean() - x_bar)**2       \n",
        "SEM_anova_table['SS']['Between Groups'] = SSTR['yearlysalary'].sum()\n",
        "\n",
        "# calculate SSE and update anova table\n",
        "SSE = (SEM.groupby('timestamp').count() - 1) * SEM.groupby('timestamp').std()**2\n",
        "SEM_anova_table['SS']['Within Groups'] = SSE['yearlysalary'].sum()\n",
        "\n",
        "# calculate SSTR and update anova table\n",
        "SSTR = SSTR['yearlysalary'].sum() + SSE['yearlysalary'].sum()\n",
        "SEM_anova_table['SS']['Total'] = SSTR\n",
        "\n",
        "# update degree of freedom\n",
        "SEM_anova_table['df']['Between Groups'] = SEM['timestamp'].nunique() - 1\n",
        "SEM_anova_table['df']['Within Groups'] = SEM.shape[0] - SEM['timestamp'].nunique()\n",
        "SEM_anova_table['df']['Total'] = SEM.shape[0] - 1\n",
        "\n",
        "# calculate MS\n",
        "SEM_anova_table['MS'] = SEM_anova_table['SS'] / SEM_anova_table['df']\n",
        "\n",
        "# calculate F \n",
        "F = SEM_anova_table['MS']['Between Groups'] / SEM_anova_table['MS']['Within Groups']\n",
        "SEM_anova_table['F']['Between Groups'] = F\n",
        "\n",
        "# p-value\n",
        "SEM_anova_table['P-value']['Between Groups'] = 1 - stats.f.cdf(F, SEM_anova_table['df']['Between Groups'], SEM_anova_table['df']['Within Groups'])\n",
        "\n",
        "# F critical \n",
        "alpha = 0.01\n",
        "# possible types \"right-tailed, left-tailed, two-tailed\"\n",
        "tail_hypothesis_type = \"two-tailed\"\n",
        "if tail_hypothesis_type == \"two-tailed\":\n",
        "    alpha /= 2\n",
        "SEM_anova_table['F crit']['Between Groups'] = stats.f.ppf(1-alpha, SEM_anova_table['df']['Between Groups'], SEM_anova_table['df']['Within Groups'])\n",
        "\n",
        "# Final ANOVA Table\n",
        "SEM_anova_table"
      ],
      "id": "9d05cf9c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"The p-value approach to hypothesis testing in the decision rule\")\n",
        "conclusion = \"Failed to reject the null hypothesis.\"\n",
        "if SEM_anova_table['P-value']['Between Groups'] <= alpha:\n",
        "    conclusion = \"Null Hypothesis is rejected.\"\n",
        "print(\"F-score is:\", SEM_anova_table['F']['Between Groups'], \" and p value is:\", SEM_anova_table['P-value']['Between Groups'])    \n",
        "print(conclusion)\n",
        "\n",
        "# Reject H0"
      ],
      "id": "95142d47",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# H₀: Year by year salary means of Data Scientist are equal.\n",
        "# H₁: Year by year salary means of Data Scientist are not equal.\n",
        "# α = 0.05\n",
        "\n",
        "# Product Manager, Hardware Engineer\n",
        "DS = df3[df3['title'] == 'Data Scientist']\n",
        "\n",
        "DS_ANOVA = [['Between Groups', '', '', '', '', '', ''], ['Within Groups', '', '', '', '', '', ''], ['Total', '', '', '', '', '', '']] \n",
        "DS_anova_table = pd.DataFrame(DS_ANOVA, columns = ['Source of Variation', 'SS', 'df', 'MS', 'F', 'P-value', 'F crit']) \n",
        "DS_anova_table.set_index('Source of Variation', inplace = True)\n",
        "\n",
        "# calculate SSTR and update anova table\n",
        "x_bar = DS['yearlysalary'].mean()\n",
        "SSTR = DS.groupby('timestamp').count() * (DS.groupby('timestamp').mean() - x_bar)**2       \n",
        "DS_anova_table['SS']['Between Groups'] = SSTR['yearlysalary'].sum()\n",
        "\n",
        "# calculate SSE and update anova table\n",
        "SSE = (DS.groupby('timestamp').count() - 1) * DS.groupby('timestamp').std()**2\n",
        "DS_anova_table['SS']['Within Groups'] = SSE['yearlysalary'].sum()\n",
        "\n",
        "# calculate SSTR and update anova table\n",
        "SSTR = SSTR['yearlysalary'].sum() + SSE['yearlysalary'].sum()\n",
        "DS_anova_table['SS']['Total'] = SSTR\n",
        "\n",
        "# update degree of freedom\n",
        "DS_anova_table['df']['Between Groups'] = DS['timestamp'].nunique() - 1\n",
        "DS_anova_table['df']['Within Groups'] = DS.shape[0] - DS['timestamp'].nunique()\n",
        "DS_anova_table['df']['Total'] = DS.shape[0] - 1\n",
        "\n",
        "# calculate MS\n",
        "DS_anova_table['MS'] = DS_anova_table['SS'] / DS_anova_table['df']\n",
        "\n",
        "# calculate F \n",
        "F = DS_anova_table['MS']['Between Groups'] / DS_anova_table['MS']['Within Groups']\n",
        "DS_anova_table['F']['Between Groups'] = F\n",
        "\n",
        "# p-value\n",
        "DS_anova_table['P-value']['Between Groups'] = 1 - stats.f.cdf(F, DS_anova_table['df']['Between Groups'], DS_anova_table['df']['Within Groups'])\n",
        "\n",
        "# F critical \n",
        "alpha = 0.01\n",
        "# possible types \"right-tailed, left-tailed, two-tailed\"\n",
        "tail_hypothesis_type = \"two-tailed\"\n",
        "if tail_hypothesis_type == \"two-tailed\":\n",
        "    alpha /= 2\n",
        "DS_anova_table['F crit']['Between Groups'] = stats.f.ppf(1-alpha, DS_anova_table['df']['Between Groups'], DS_anova_table['df']['Within Groups'])\n",
        "\n",
        "# Final ANOVA Table\n",
        "DS_anova_table"
      ],
      "id": "55316398",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"The p-value approach to hypothesis testing in the decision rule\")\n",
        "conclusion = \"Failed to reject the null hypothesis.\"\n",
        "if DS_anova_table['P-value']['Between Groups'] <= alpha:\n",
        "    conclusion = \"Null Hypothesis is rejected.\"\n",
        "print(\"F-score is:\", DS_anova_table['F']['Between Groups'], \" and p value is:\", DS_anova_table['P-value']['Between Groups'])    \n",
        "print(conclusion)\n",
        "\n",
        "# Reject H0"
      ],
      "id": "1f6c0f0c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# H₀: Year by year salary means of Product Manager are equal.\n",
        "# H₁: Year by year salary means of Product Manager are not equal.\n",
        "# α = 0.05\n",
        "\n",
        "PM = df3[df3['title'] == 'Product Manager']\n",
        "\n",
        "PM_ANOVA = [['Between Groups', '', '', '', '', '', ''], ['Within Groups', '', '', '', '', '', ''], ['Total', '', '', '', '', '', '']] \n",
        "PM_anova_table = pd.DataFrame(PM_ANOVA, columns = ['Source of Variation', 'SS', 'df', 'MS', 'F', 'P-value', 'F crit']) \n",
        "PM_anova_table.set_index('Source of Variation', inplace = True)\n",
        "\n",
        "# calculate SSTR and update anova table\n",
        "x_bar = PM['yearlysalary'].mean()\n",
        "SSTR = PM.groupby('timestamp').count() * (PM.groupby('timestamp').mean() - x_bar)**2       \n",
        "PM_anova_table['SS']['Between Groups'] = SSTR['yearlysalary'].sum()\n",
        "\n",
        "# calculate SSE and update anova table\n",
        "SSE = (PM.groupby('timestamp').count() - 1) * PM.groupby('timestamp').std()**2\n",
        "PM_anova_table['SS']['Within Groups'] = SSE['yearlysalary'].sum()\n",
        "\n",
        "# calculate SSTR and update anova table\n",
        "SSTR = SSTR['yearlysalary'].sum() + SSE['yearlysalary'].sum()\n",
        "PM_anova_table['SS']['Total'] = SSTR\n",
        "\n",
        "# update degree of freedom\n",
        "PM_anova_table['df']['Between Groups'] = PM['timestamp'].nunique() - 1\n",
        "PM_anova_table['df']['Within Groups'] = PM.shape[0] - PM['timestamp'].nunique()\n",
        "PM_anova_table['df']['Total'] = PM.shape[0] - 1\n",
        "\n",
        "# calculate MS\n",
        "PM_anova_table['MS'] = PM_anova_table['SS'] / PM_anova_table['df']\n",
        "\n",
        "# calculate F \n",
        "F = PM_anova_table['MS']['Between Groups'] / PM_anova_table['MS']['Within Groups']\n",
        "PM_anova_table['F']['Between Groups'] = F\n",
        "\n",
        "# p-value\n",
        "PM_anova_table['P-value']['Between Groups'] = 1 - stats.f.cdf(F, PM_anova_table['df']['Between Groups'], PM_anova_table['df']['Within Groups'])\n",
        "\n",
        "# F critical \n",
        "alpha = 0.01\n",
        "# possible types \"right-tailed, left-tailed, two-tailed\"\n",
        "tail_hypothesis_type = \"two-tailed\"\n",
        "if tail_hypothesis_type == \"two-tailed\":\n",
        "    alpha /= 2\n",
        "PM_anova_table['F crit']['Between Groups'] = stats.f.ppf(1-alpha, PM_anova_table['df']['Between Groups'], PM_anova_table['df']['Within Groups'])\n",
        "\n",
        "# Final ANOVA Table\n",
        "PM_anova_table"
      ],
      "id": "e638144f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"The p-value approach to hypothesis testing in the decision rule\")\n",
        "conclusion = \"Failed to reject the null hypothesis.\"\n",
        "if PM_anova_table['P-value']['Between Groups'] <= alpha:\n",
        "    conclusion = \"Null Hypothesis is rejected.\"\n",
        "print(\"F-score is:\", PM_anova_table['F']['Between Groups'], \" and p value is:\", PM_anova_table['P-value']['Between Groups'])    \n",
        "print(conclusion)\n",
        "\n",
        "# Reject H0"
      ],
      "id": "c9426f92",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# H₀: Year by year salary means of Hardware Engineer are equal.\n",
        "# H₁: Year by year salary means of Hardware Engineer are not equal.\n",
        "# α = 0.05\n",
        "\n",
        "HE = df3[df3['title'] == 'Hardware Engineer']\n",
        "\n",
        "HE_ANOVA = [['Between Groups', '', '', '', '', '', ''], ['Within Groups', '', '', '', '', '', ''], ['Total', '', '', '', '', '', '']] \n",
        "HE_anova_table = pd.DataFrame(HE_ANOVA, columns = ['Source of Variation', 'SS', 'df', 'MS', 'F', 'P-value', 'F crit']) \n",
        "HE_anova_table.set_index('Source of Variation', inplace = True)\n",
        "\n",
        "# calculate SSTR and update anova table\n",
        "x_bar = HE['yearlysalary'].mean()\n",
        "SSTR = HE.groupby('timestamp').count() * (HE.groupby('timestamp').mean() - x_bar)**2       \n",
        "HE_anova_table['SS']['Between Groups'] = SSTR['yearlysalary'].sum()\n",
        "\n",
        "# calculate SSE and update anova table\n",
        "SSE = (HE.groupby('timestamp').count() - 1) * HE.groupby('timestamp').std()**2\n",
        "HE_anova_table['SS']['Within Groups'] = SSE['yearlysalary'].sum()\n",
        "\n",
        "# calculate SSTR and update anova table\n",
        "SSTR = SSTR['yearlysalary'].sum() + SSE['yearlysalary'].sum()\n",
        "HE_anova_table['SS']['Total'] = SSTR\n",
        "\n",
        "# update degree of freedom\n",
        "HE_anova_table['df']['Between Groups'] = HE['timestamp'].nunique() - 1\n",
        "HE_anova_table['df']['Within Groups'] = HE.shape[0] - HE['timestamp'].nunique()\n",
        "HE_anova_table['df']['Total'] = HE.shape[0] - 1\n",
        "\n",
        "# calculate MS\n",
        "HE_anova_table['MS'] = HE_anova_table['SS'] / HE_anova_table['df']\n",
        "\n",
        "# calculate F \n",
        "F = HE_anova_table['MS']['Between Groups'] / HE_anova_table['MS']['Within Groups']\n",
        "HE_anova_table['F']['Between Groups'] = F\n",
        "\n",
        "# p-value\n",
        "HE_anova_table['P-value']['Between Groups'] = 1 - stats.f.cdf(F, HE_anova_table['df']['Between Groups'], HE_anova_table['df']['Within Groups'])\n",
        "\n",
        "# F critical \n",
        "alpha = 0.01\n",
        "# possible types \"right-tailed, left-tailed, two-tailed\"\n",
        "tail_hypothesis_type = \"two-tailed\"\n",
        "if tail_hypothesis_type == \"two-tailed\":\n",
        "    alpha /= 2\n",
        "HE_anova_table['F crit']['Between Groups'] = stats.f.ppf(1-alpha, HE_anova_table['df']['Between Groups'], HE_anova_table['df']['Within Groups'])\n",
        "\n",
        "# Final ANOVA Table\n",
        "HE_anova_table"
      ],
      "id": "a4698a6e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"The p-value approach to hypothesis testing in the decision rule\")\n",
        "conclusion = \"Failed to reject the null hypothesis.\"\n",
        "if HE_anova_table['P-value']['Between Groups'] <= alpha:\n",
        "    conclusion = \"Null Hypothesis is rejected.\"\n",
        "print(\"F-score is:\", HE_anova_table['F']['Between Groups'], \" and p value is:\", HE_anova_table['P-value']['Between Groups'])    \n",
        "print(conclusion)\n",
        "\n",
        "# Reject H0"
      ],
      "id": "cd2f60b2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "According to ANOVA, the salary by title over time is statistically significant, which means salary over time per each job position is not equal.\n",
        "\n",
        "## How large is the wage disparity between gender?"
      ],
      "id": "695c7bc3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.boxplot(data=df3,x = 'gender', y = 'yearlysalary')\n",
        "plt.title(\"Salary by Gender\")\n",
        "plt.ylim(0,500000,25000)"
      ],
      "id": "337be63a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ANOVA Test on Gender Feature"
      ],
      "id": "89facb63"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# H₀: Salary by gender are equal.\n",
        "# H₁: Salary by gender are not equal.\n",
        "# α = 0.05\n",
        "\n",
        "gender_ANOVA = [['Between Groups', '', '', '', '', '', ''], ['Within Groups', '', '', '', '', '', ''], ['Total', '', '', '', '', '', '']] \n",
        "gender_anova_table = pd.DataFrame(gender_ANOVA, columns = ['Source of Variation', 'SS', 'df', 'MS', 'F', 'P-value', 'F crit']) \n",
        "gender_anova_table.set_index('Source of Variation', inplace = True)\n",
        "\n",
        "# calculate SSTR and update anova table\n",
        "x_bar = df3['yearlysalary'].mean()\n",
        "SSTR = df3.groupby('gender').count() * (df3.groupby('gender').mean() - x_bar)**2       \n",
        "gender_anova_table['SS']['Between Groups'] = SSTR['yearlysalary'].sum()\n",
        "\n",
        "# calculate SSE and update anova table\n",
        "SSE = (df3.groupby('gender').count() - 1) * df3.groupby('gender').std()**2\n",
        "gender_anova_table['SS']['Within Groups'] = SSE['yearlysalary'].sum()\n",
        "\n",
        "# calculate SSTR and update anova table\n",
        "SSTR = SSTR['yearlysalary'].sum() + SSE['yearlysalary'].sum()\n",
        "gender_anova_table['SS']['Total'] = SSTR\n",
        "\n",
        "# update degree of freedom\n",
        "gender_anova_table['df']['Between Groups'] = df3['gender'].nunique() - 1\n",
        "gender_anova_table['df']['Within Groups'] = df3.shape[0] - df3['timestamp'].nunique()\n",
        "gender_anova_table['df']['Total'] = df3.shape[0] - 1\n",
        "\n",
        "# calculate MS\n",
        "gender_anova_table['MS'] = gender_anova_table['SS'] / gender_anova_table['df']\n",
        "\n",
        "# calculate F \n",
        "F = gender_anova_table['MS']['Between Groups'] / gender_anova_table['MS']['Within Groups']\n",
        "gender_anova_table['F']['Between Groups'] = F\n",
        "\n",
        "# p-value\n",
        "gender_anova_table['P-value']['Between Groups'] = 1 - stats.f.cdf(F, gender_anova_table['df']['Between Groups'], gender_anova_table['df']['Within Groups'])\n",
        "\n",
        "# F critical \n",
        "alpha = 0.05\n",
        "# possible types \"right-tailed, left-tailed, two-tailed\"\n",
        "tail_hypothesis_type = \"two-tailed\"\n",
        "if tail_hypothesis_type == \"two-tailed\":\n",
        "    alpha /= 2\n",
        "gender_anova_table['F crit']['Between Groups'] = stats.f.ppf(1-alpha, gender_anova_table['df']['Between Groups'], gender_anova_table['df']['Within Groups'])\n",
        "\n",
        "# Final ANOVA Table\n",
        "gender_anova_table"
      ],
      "id": "d8c27a17",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conclusion of ANOVA Test of Gender Feature "
      ],
      "id": "8de7f1dd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"The p-value approach to hypothesis testing in the decision rule\")\n",
        "conclusion = \"Failed to reject the null hypothesis.\"\n",
        "if gender_anova_table['P-value']['Between Groups'] <= alpha:\n",
        "    conclusion = \"Null Hypothesis is rejected.\"\n",
        "print(\"F-score is:\", gender_anova_table['F']['Between Groups'], \" and p value is:\", gender_anova_table['P-value']['Between Groups'])    \n",
        "print(conclusion)\n",
        "\n",
        "# Reject H0"
      ],
      "id": "dee7ff07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Is there a significant difference between the yearly salary in top 10 companies and the yearly salary in not-top-10 companies?\n",
        "\n",
        "List all the companys in this dataframe"
      ],
      "id": "9ec05b1a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"the unique values:\\n{pd.unique(df3.company)}\")"
      ],
      "id": "385a5e85",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Independent-Sample T Test (2 groups)\n",
        "\n",
        "Top 10 companies in the United States (https://fortune.com/fortune500/)\n",
        "\n",
        "H0: The means for the two populations are equal.\n",
        "H1: The means for the two populations are not equal.\n"
      ],
      "id": "6c296478"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "top10 = df3[df3.company.isin([\"Apple\",\"apple\",\"APPLE\",\"Walmart Labs\",\"Walmart\",\"walmart\",\"Amazon\",\"amazon\",\"AMAZON\",\"CVS health\",\"cvs health\",\"CVS Health\",\"UnitedHealth Group\",\"ExxonMobil\"\n",
        "\"McKesson\"])]\n",
        "\n",
        "not10 = df3[~df3.company.isin([\"Apple\",\"apple\",\"APPLE\",\"Walmart Labs\",\"Walmart\",\"walmart\",\"Amazon\",\"amazon\",\"AMAZON\",\"CVS health\",\"cvs health\",\"CVS Health\",\"UnitedHealth Group\",\"ExxonMobil\"\n",
        "\"McKesson\"])]\n",
        "\n",
        "df3['topcompany']=np.where((df3['company'].isin([\"Apple\",\"apple\",\"APPLE\",\"Walmart Labs\",\"Walmart\",\"walmart\",\"Amazon\",\"amazon\",\"AMAZON\",\"CVS health\",\"cvs health\",\"CVS Health\",\"UnitedHealth Group\",\"ExxonMobil\", \"McKesson\"])) & (~df3['company'].isin([120,128])),1,0)"
      ],
      "id": "974c70fb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Distribution of yearly salary"
      ],
      "id": "8bf35127"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.violinplot(x=df3['topcompany'], y=df3[\"yearlysalary\"]).set(title='Distribution of yearly salary')"
      ],
      "id": "5b9068f8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "T-Test"
      ],
      "id": "68133a73"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "summary, results = rp.ttest(group1= top10['yearlysalary'], group1_name= \"top10\",\n",
        "                            group2= not10['yearlysalary'], group2_name= \"not10\")\n",
        "\n",
        "print(summary)\n",
        "print(results)"
      ],
      "id": "026569e5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The average yearlysalary for top 10 company, M= 355205.521 , was statistically signigicantly higher than those not-top-10 companies(M= 320767.298); t= 23.239, p < 0.05\n",
        "\n",
        "\n",
        "## Is working for more years in the same company affect the salary? \n",
        "\n",
        "Distribution of yeas at company"
      ],
      "id": "52c05246"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.histplot(data=df3, x=\"yearsatcompany\", bins = 8, binrange = (0.5, 8.5)).set_title('Years at Company')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "sns.boxplot(x=\"topcompany\", y=\"yearsatcompany\", data=df3, palette=\"Set1\", width=0.5).set_title('Years at Company')\n",
        "plt.show()"
      ],
      "id": "85348753",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Scatterplot & Linear Regression Fit Line"
      ],
      "id": "e76c3b83"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.regplot(x=df3[\"yearsatcompany\"], y=df3[\"yearlysalary\"], line_kws={\"color\":\"r\",\"alpha\":0.7,\"lw\":2}).set_title('After removing outliers')\n",
        "plt.show()"
      ],
      "id": "8c0413ab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "calculate the Pearson's correlation between two variables"
      ],
      "id": "c30e4bfd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from scipy.stats import pearsonr\n",
        "corr, _ = pearsonr(df3['yearsatcompany'], df3['yearlysalary'])\n",
        "print('Pearsons correlation: %.3f' % corr)"
      ],
      "id": "a311c2ee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## In the recent five years, the average salary keeps the same?\n",
        "\n",
        "Distribution of yearly by timestamp"
      ],
      "id": "32bcc01e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.violinplot(x=df3['timestamp'], y=df3[\"yearlysalary\"]).set(title='Distribution of yearly salary in 4 years')"
      ],
      "id": "5b9f6f07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Q-Q Plot (Normality Assumption Check)"
      ],
      "id": "d3b4e5b6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "unique_time = df3['timestamp'].unique()\n",
        "for timestamp in unique_time:\n",
        "    stats.probplot(df3[df3['timestamp'] == timestamp]['yearlysalary'], dist=\"norm\", plot=plt)\n",
        "    plt.title(\"Probability Plot - \" +  timestamp)\n",
        "    plt.show()"
      ],
      "id": "f22a6af8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the above figure, we may assume that the data for each group falls roughly on a straight line.\n",
        "\n",
        "\n",
        "ANOVA Test"
      ],
      "id": "7a929476"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Hypothesis Testing\n",
        "# H₀: μ1= μ2 = μ3 = μ4\n",
        "# H₁: Not all yearlysalary means are equal\n",
        "# α = 0.05\n",
        "\n",
        "\n",
        "# Create ANOVA backbone table\n",
        "data = [['Between Groups', '', '', '', '', '', ''], ['Within Groups', '', '', '', '', '', ''], ['Total', '', '', '', '', '', '']] \n",
        "anova_table = pd.DataFrame(data, columns = ['Source of Variation', 'SS', 'df', 'MS', 'F', 'P-value', 'F crit']) \n",
        "anova_table.set_index('Source of Variation', inplace = True)\n",
        "\n",
        "# calculate SSTR and update anova table\n",
        "x_bar = df3['yearlysalary'].mean()\n",
        "SSTR = df3.groupby('timestamp').count() * (df3.groupby('timestamp').mean() - x_bar)**2\n",
        "anova_table['SS']['Between Groups'] = SSTR['yearlysalary'].sum()\n",
        "\n",
        "# calculate SSE and update anova table\n",
        "SSE = (df3.groupby('timestamp').count() - 1) * df3.groupby('timestamp').std()**2\n",
        "anova_table['SS']['Within Groups'] = SSE['yearlysalary'].sum()\n",
        "\n",
        "# calculate SSTR and update anova table\n",
        "SSTR = SSTR['yearlysalary'].sum() + SSE['yearlysalary'].sum()\n",
        "anova_table['SS']['Total'] = SSTR\n",
        "\n",
        "# update degree of freedom\n",
        "anova_table['df']['Between Groups'] = df3['timestamp'].nunique() - 1\n",
        "anova_table['df']['Within Groups'] = df3.shape[0] - df3['timestamp'].nunique()\n",
        "anova_table['df']['Total'] = df3.shape[0] - 1\n",
        "\n",
        "# calculate MS\n",
        "anova_table['MS'] = anova_table['SS'] / anova_table['df']\n",
        "\n",
        "# calculate F \n",
        "F = anova_table['MS']['Between Groups'] / anova_table['MS']['Within Groups']\n",
        "anova_table['F']['Between Groups'] = F\n",
        "\n",
        "# p-value\n",
        "anova_table['P-value']['Between Groups'] = 1 - stats.f.cdf(F, anova_table['df']['Between Groups'], anova_table['df']['Within Groups'])\n",
        "\n",
        "# F critical \n",
        "alpha = 0.05\n",
        "# possible types \"right-tailed, left-tailed, two-tailed\"\n",
        "tail_hypothesis_type = \"two-tailed\"\n",
        "if tail_hypothesis_type == \"two-tailed\":\n",
        "    alpha /= 2\n",
        "anova_table['F crit']['Between Groups'] = stats.f.ppf(1-alpha, anova_table['df']['Between Groups'], anova_table['df']['Within Groups'])\n",
        "\n",
        "# Final ANOVA Table\n",
        "anova_table"
      ],
      "id": "273b0577",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ANOVA Test Result"
      ],
      "id": "83f4130e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"The p-value approach to hypothesis testing in the decision rule\")\n",
        "conclusion = \"Failed to reject the null hypothesis.\"\n",
        "if anova_table['P-value']['Between Groups'] <= alpha:\n",
        "    conclusion = \"Null Hypothesis is rejected.\"\n",
        "print(\"F-score is:\", anova_table['F']['Between Groups'], \" and p value is:\", anova_table['P-value']['Between Groups'])    \n",
        "print(conclusion)\n",
        "\n",
        "# Rejact H0"
      ],
      "id": "d0352ebd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How much do the employee's experience affect his or her salary?\n"
      ],
      "id": "f4c86c9f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.barplot(data=df3,x = 'yearsofexperience',y ='yearlysalary')\n",
        "plt.title(\"Yearly Salary vs Year of Experience\")\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.ylim(0,400000,25000)\n",
        "plt.xlim(0,35,5)"
      ],
      "id": "813ff396",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.lineplot(data=df3,x = 'yearsofexperience',y ='yearlysalary')\n",
        "plt.title(\"Yearly Salary vs Year of Experience\")\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.ylim(100000,1000000,50000)\n",
        "plt.xlim(0,20,5)"
      ],
      "id": "a4be02ab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "•\tThere are lot of fluctuations in the salary of employees in the initial 8-9 years, because of some reasons like constant shifting companies and less salaries in the career beginning and have a constant growth in the salary after that.\n",
        "\n",
        "***Pearson’s Correlation Matrix:***\n",
        "\n",
        "Pearson's correlation is utilized when you have two quantitative variables and you wish to see if there is a linear relationship between those variables.\n",
        "\n",
        "The three possible research hypotheses state whether or not there is a linear relationship between the two variables.\n",
        "1)\tThe variables are positively correlated (as one variable gets larger so does the other),\n",
        "2)\tThe variables are negatively correlated (as one variable gets larger the other gets smaller),\n",
        "3)\tThe variables are not correlated (there is no relationship between the two variables).ter that.\n"
      ],
      "id": "a9d9ba69"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Pearson Correlation Matrix\n",
        "pearsoncorr=dataframe.corr(method='pearson')\n",
        "pearsoncorr"
      ],
      "id": "8dd41b70",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Pearsons Correlation matrix Using Heatmap\n",
        "corr_matrix = dataframe.corr()\n",
        "print(corr_matrix)\n",
        "\n",
        "plt.figure(figsize=(12,10))\n",
        "sns.heatmap(corr_matrix, cmap=plt.cm.CMRmap_r,annot=True)\n",
        "plt.show() "
      ],
      "id": "cc0a3e93",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The correlation between yearlysalary and yearsofexperiecne is 0.36 which means that both the variables are moderatel correlated to each other.\n",
        "\n",
        "# Feature Engineering:\n",
        "\n",
        "Feature engineering is a machine learning approach that uses data to generate new variables that were not included in the training set. It can develop new features for both supervised and unsupervised learning, with the objective of simplifying and speeding up data transformations while simultaneously boosting model correctness.\n",
        "\n",
        "The process of designing artificial features into an algorithm is referred to as feature engineering. These fake traits are then employed by the algorithm to increase its performance, or to yield better results. Data scientists spend the majority of their time working with data, thus accuracy is critical.\n",
        "\n",
        "When feature engineering operations are carried out appropriately, the final dataset is optimum and contains all of the relevant aspects influencing the business challenge. As a consequence of these datasets, the most accurate prediction models and the most relevant insights are created.\n",
        "\n",
        "\n",
        "## Creating Dummy Variables using One Hot Encoding for Company and Location Features\n",
        "\n",
        "***One Hot Encoding***\n",
        "\n",
        "One hot encoding can be defined as the important process of changing the categorical data variables to be delivered to machine and deep learning algorithms which in turn increase predictions as well as classification accuracy of a model.\n",
        "\n",
        "Checking for Unique Variables"
      ],
      "id": "8ff4750a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Checking for Unique Variables\n",
        "for col in dataframe.columns:\n",
        "    print(col, ':', len(df3[col].unique()))"
      ],
      "id": "8962f215",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Considering the top 20 companies of Multicategorical Feature Company "
      ],
      "id": "ecb89890"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Considering the top 20 companies of Multicategorical Feature Company \n",
        "df3.company.value_counts().sort_values(ascending=False).head(20)\n",
        "#df3.company.value_counts().sort_values(ascending=False).tail(20)"
      ],
      "id": "95ca3ceb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating an array of top 20 companies names"
      ],
      "id": "53f774ed"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Creating an array of top 20 companies names\n",
        "top_20=[x for x in df3.company.value_counts().sort_values(ascending=False).head(20).index]\n",
        "top_20"
      ],
      "id": "c9adfb9d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Function for performing one hot encoding"
      ],
      "id": "890419c1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def one_hot_top_x(df3,variable,top_x_labels):\n",
        "    for label in top_x_labels:\n",
        "        df3[variable+'_'+label]=np.where(df3[variable]==label,1,0)\n",
        "\n",
        "one_hot_top_x(df3,'company', top_20)\n",
        "df3.head()"
      ],
      "id": "5b21b7dd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "top_20=[x for x in df3.location.value_counts().sort_values(ascending=False).head(20).index]\n",
        "one_hot_top_x(df3,'location',top_20)"
      ],
      "id": "11be7939",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating Dummy Variables using pandas get_dummies function for gender, timestamp, title features\n",
        "\n",
        "***Get_dummies***\n",
        "Pandas get_dummies() is used for data manipulation. It converts categorical data into dummy or indicator variables.  A dummy or indicator variable can have a value of 0 or 1.\n"
      ],
      "id": "2123fccd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Creating dummies for gender feature\n",
        "df_dummies = pd.get_dummies(df3, columns=['gender'])\n",
        "\n",
        "# Creating dummies for timestamp feature\n",
        "df_dummies1 = pd.get_dummies(df_dummies, columns=['timestamp'])\n",
        "\n",
        "df_dummies2 = pd.get_dummies(df_dummies1, columns=['title'])\n",
        "\n",
        "# After applying One Hot Encoding on company and location and Creating Dummies for gender, timestamp and title\n",
        "df_dummies2.shape\n",
        "\n",
        "# To Replace ' ' with '' in column heading\n",
        "df_dummies2.columns=df_dummies2.columns.str.replace(' ','')\n",
        "\n",
        "# To Replace ',' with '_' in column heading\n",
        "df_dummies2.columns=df_dummies2.columns.str.replace(',','_')\n",
        "df_dummies2.head()"
      ],
      "id": "04b4eb6d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predictive Analysis\n",
        "\n",
        "***Linear Regression***\n",
        "\n",
        "Linear regression is a technique that offers a linear connection between an independent variable and a dependent variable to predict the outcome of future events. It is a statistical approach used in data science and machine learning for predictive analysis.\n",
        "\n",
        "## Linear Regression Model\n"
      ],
      "id": "25bf9a97"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import the Libraries for Train_Test_Split from scikit learn:\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Defining X and y Variables for Train and Test Split\n",
        "X = df_dummies2.loc[:,['yearsofexperience','company_Amazon','company_Microsoft','company_Google','company_Facebook','company_Apple','company_Oracle','company_Salesforce','company_IBM','company_Intel','company_Cisco','company_CapitalOne','company_Uber','company_VMware','company_LinkedIn','company_JPMorganChase','company_GoldmanSachs','company_Qualcomm','company_Intuit','company_Bloomberg','company_PayPal','location_Seattle_WA','location_SanFrancisco_CA','location_NewYork_NY','location_Redmond_WA','location_Sunnyvale_CA','location_MountainView_CA','location_SanJose_CA','location_Austin_TX','location_Bangalore_KA_India','location_Cupertino_CA','location_MenloPark_CA','location_Boston_MA','location_London_EN_UnitedKingdom','location_SantaClara_CA','location_PaloAlto_CA','location_Chicago_IL','location_SanDiego_CA','location_Toronto_ON_Canada','location_Bellevue_WA','location_Bengaluru_KA_India','gender_Female','gender_Male','gender_Other','timestamp_2018','timestamp_2019','timestamp_2020','timestamp_2021','title_BusinessAnalyst','title_DataScientist','title_HardwareEngineer','title_HumanResources','title_ManagementConsultant','title_Marketing','title_MechanicalEngineer','title_ProductDesigner','title_ProductManager','title_Recruiter','title_Sales','title_SoftwareEngineer','title_SoftwareEngineeringManager','title_SolutionArchitect','title_TechnicalProgramManager',]]\n",
        "y = df_dummies2[['yearlysalary']]\n",
        "\n",
        "# Splitling the data into Train and test Data\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.8,random_state=100)"
      ],
      "id": "f943b329",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Importing Linear Regression model from scikit learn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lr = LinearRegression()\n",
        "# Fitting X train and y train in Linear Regression\n",
        "lr.fit(X_train,y_train)"
      ],
      "id": "74bcca0a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Predicting the value of y\n",
        "y_pred = lr.predict(X_test)"
      ],
      "id": "c288b7b8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Importing metrics for the evaluation of the model\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "# calculate Mean square error\n",
        "mse = mean_squared_error(y_test,y_pred)\n",
        "# Calculate R square vale\n",
        "rsq = r2_score(y_test,y_pred)\n",
        "print('Mean Squared Error of Linear Regression :',round(mse,5))\n",
        "print('R Square value of Linear Regression :',round(rsq,5))\n",
        "print(\"The Training R Square value is: %2f\"%lr.score(X_train,y_train))\n",
        "print(\"The Testing R Square value is: %2f\"%lr.score(X_test,y_test))"
      ],
      "id": "af47f56c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Intercepts of Linear Regression:\",lr.intercept_)\n",
        "print(\"Coefficients of Linear Regression:\",lr.coef_)"
      ],
      "id": "78c60990",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import statsmodels\n",
        "import statsmodels.formula.api as smf\n",
        "lin_model = smf.ols(formula= 'yearlysalary~yearsofexperience+company_Amazon+company_Microsoft+company_Google+company_Facebook+company_Apple+company_Oracle+company_Salesforce+company_IBM+company_Intel+company_Cisco+company_CapitalOne+company_Uber+company_VMware+company_LinkedIn+company_JPMorganChase+company_GoldmanSachs+company_Qualcomm+company_Intuit+company_Bloomberg+company_PayPal+location_Seattle_WA+location_SanFrancisco_CA+location_NewYork_NY+location_Redmond_WA+location_Sunnyvale_CA+location_MountainView_CA+location_SanJose_CA+location_Austin_TX+location_Bangalore_KA_India+location_Cupertino_CA+location_MenloPark_CA+location_Boston_MA+location_London_EN_UnitedKingdom+location_SantaClara_CA+location_PaloAlto_CA+location_Chicago_IL+location_SanDiego_CA+location_Toronto_ON_Canada+location_Bellevue_WA+location_Bengaluru_KA_India+gender_Female+gender_Male+gender_Other+timestamp_2018+timestamp_2019+timestamp_2020+timestamp_2021+title_BusinessAnalyst+title_DataScientist+title_HardwareEngineer+title_HumanResources+title_ManagementConsultant+title_Marketing+title_MechanicalEngineer+title_ProductDesigner+title_ProductManager+title_Recruiter+title_Sales+title_SoftwareEngineer+title_SoftwareEngineeringManager+title_SolutionArchitect+title_TechnicalProgramManager',data=df_dummies2).fit()\n",
        "lin_model.summary()"
      ],
      "id": "ed0fc16a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random Forest Regression Model\n",
        "\n",
        "***Random Forest Regression***\n",
        "\n",
        "Random Forest Regression is a supervised learning technique that does regression using the ensemble learning method. Ensemble learning method is a methodology that integrates predictions from numerous machine learning algorithms to generate a more accurate forecast than a single model.\n",
        "Each tree is built from a separate set of rows, and a new set of characteristics is chosen for splitting at each node. Each of the trees provides a unique forecast. These forecasts are then averaged to get a single outcome.\n"
      ],
      "id": "46bceb5a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Defining X and y Variables for Train and Test Split\n",
        "X = df_dummies2.loc[:,['yearsofexperience','company_Amazon','company_Microsoft','company_Google','company_Facebook','company_Apple','company_Oracle','company_Salesforce','company_IBM','company_Intel','company_Cisco','company_CapitalOne','company_Uber','company_VMware','company_LinkedIn','company_JPMorganChase','company_GoldmanSachs','company_Qualcomm','company_Intuit','company_Bloomberg','company_PayPal','location_Seattle_WA','location_SanFrancisco_CA','location_NewYork_NY','location_Redmond_WA','location_Sunnyvale_CA','location_MountainView_CA','location_SanJose_CA','location_Austin_TX','location_Bangalore_KA_India','location_Cupertino_CA','location_MenloPark_CA','location_Boston_MA','location_London_EN_UnitedKingdom','location_SantaClara_CA','location_PaloAlto_CA','location_Chicago_IL','location_SanDiego_CA','location_Toronto_ON_Canada','location_Bellevue_WA','location_Bengaluru_KA_India','gender_Female','gender_Male','gender_Other','timestamp_2018','timestamp_2019','timestamp_2020','timestamp_2021','title_BusinessAnalyst','title_DataScientist','title_HardwareEngineer','title_HumanResources','title_ManagementConsultant','title_Marketing','title_MechanicalEngineer','title_ProductDesigner','title_ProductManager','title_Recruiter','title_Sales','title_SoftwareEngineer','title_SoftwareEngineeringManager','title_SolutionArchitect','title_TechnicalProgramManager',]]\n",
        "y = df_dummies2[['yearlysalary']]\n",
        "\n",
        "# Splitling the data into Train and test Data\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.8,random_state=100)"
      ],
      "id": "6f73d50c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import the regressor library from sklearn\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "  \n",
        " # create regressor object\n",
        "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
        "  \n",
        "# fit the regressor with x and y data\n",
        "regressor.fit(X, y)"
      ],
      "id": "693ba0a2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Pred=regressor.predict(X)"
      ],
      "id": "80d3b3e9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "R_Square_Score=r2_score(y,Pred)\n",
        "\n",
        "Mean_Square_error=mean_squared_error(y,Pred)\n",
        "print('Mean Squared Error of Random Forest Regression: ',round(Mean_Square_error,5))\n",
        "print('R Square value of Random Forest Regression:',round(R_Square_Score,6))\n",
        "print(\"The Training R Square value is: %2f\"%regressor.score(X_train,y_train))\n",
        "print(\"The Testing R Square value is: %2f\"%regressor.score(X_test,y_test))"
      ],
      "id": "3b041c81",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion\n"
      ],
      "id": "0b0658a4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 1.\tThe means salary of each job position is different from each other.\n",
        "# 2.\tThe average salary of gender is not equal\n",
        "# 3.\tThe average yearly salary in the US top 10 companies was higher than not-top-10 companies’ average yearly salary\n",
        "# 4.\tWorking in the same company for more years does not mean those people have higher salaries\n",
        "# 5.\tThe means of yearly salary from 2018 to 2021 are not equal\n",
        "# 6.\tYearly salary won’t affect much by years of experience.\n",
        "# 7.\tRandom Forest Regression is a better model with high R Square when compared to the Linear Regression"
      ],
      "id": "8464a9f0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}